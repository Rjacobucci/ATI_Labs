---
title: "Group Search pt.2"
output: pdf_document
---
This is a continuation of various methods that have been proposed in the last 10 years for searching for subgroups, either observed or unobserved, in the dataset. Most of these are in relation to measurement invariance of differential item functioning.

# Strucchange
Easier to understand article:

http://journal.frontiersin.org/article/10.3389/fpsyg.2014.00438/abstract

More papers at Edgar Merkle's site: 

http://semtools.r-forge.r-project.org/

estimation method depends on what type of covariate you have. 

Need two new packages
```{r,message=FALSE}
library(psychotools)
library(OpenMx)
library(strucchange)
library(lavaan)
HS <- HolzingerSwineford1939
```

The One Factor Model from before
```{r,warning=F,message=F,error=FALSE}
model1.lav <- '
F1 =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
'
lav.fit <- cfa(model1.lav, HS,meanstructure=T)
#summary(lav.fit,fit=T)

```

Has problems with missing data, so can only use complete cases
(BTW, no missing in HS, but for demo purposes)
```{r}
comp <- complete.cases(HS)
HS.comp <- HS[comp,]
```

Test for continuous covariates:
1. "DM"
2. "CvM"
3. "maxLM"

Test for ordinal covariates: (note, takes much much longer -- similar to semtree with ordinal)
1. "maxLMo"
2. "WDMo"

Lets run it -- starting with no restrictions and searching 
```{r,eval=FALSE}
# can't run, not large enough sample size for 6 groups
#lav.fitGroup1 <- cfa(model1.lav, HS,meanstructure=T,group="ageyr",
#                    group.equal="loadings")


sctest(lav.fit, order.by = HS.comp$ageyr, parm = 1:8,
         vcov = "info", functional = "maxLMo",plot=T)


sctest(lav.fit, order.by = HS.comp$ageyr,
                            parm = 1:8, vcov = "info",
                            functional = "WDMo",plot=T)
```


```{r}
lav.fitGroup2 <- cfa(model1.lav, HS.comp,meanstructure=T,group="school",
                    group.equal=c("loadings","intercepts"))

#summary(lav.fitGroup2,fit=T)
anova(lav.fit,lav.fitGroup2)
# what are offending parameters
mod <- modindices(lav.fitGroup2)
mod[mod$op == "~1" & mod$mi > 10,]
```

2 Intercepts seem to be big problem

Do we get same answer with strucchange

```{r}
# get which parameters to fix: 
# coef(lav.fitGroup2)
# intercepts 19:27
sctest(lav.fitGroup2, order.by = HS.comp$school,
                            parm = c(1:8,19:27), vcov = "info",
                            functional = "LMuo",plot=T)

# what if we change the model
model5.lav <- '
F1 =~ x1 + x2 + x3 # + x7 + x9
F2 =~ x4 + x5 + x6 # + x1
F3 =~ x7 + x8 + x9
'
lav.fitGroup5 <- cfa(model5.lav, HS,meanstructure=T,group="school",group.equal=c("loadings","intercepts"))
coef(lav.fitGroup5)
sctest(lav.fitGroup5, order.by = HS.comp$school,
                            parm = c(1:6,22:30), vcov = "info",
                            functional = "LMuo",plot=T)

#sctest(lav.fitGroup5, order.by = HS.comp$school,
#                            parm = c(1:9,25:33), vcov = "info",
#                            functional = "LMuo",plot=T)

lav.fitGroup55 <- cfa(model5.lav, HS,meanstructure=T,group="school",group.equal=c("loadings"))
lav.fitGroup555 <- cfa(model5.lav, HS,meanstructure=T,group="school")
lavTestLRT(lav.fitGroup555,lav.fitGroup55,lav.fitGroup5) # intercepts are prob

mod2 <- modificationIndices(lav.fitGroup5)
mod2[mod2$op == "~1" & mod2$mi > 10,]
```



# Rasch Trees
SEM Trees, but for binary variables (rasch model)\

http://cran.r-project.org/web/packages/psychotree/vignettes/raschtree.pdf

http://link.springer.com/article/10.1007%2Fs11336-013-9388-3#page-1

You have to set up the dataset a certain way -- its a little wonky
```{r}
library(psychotree)
library(colorspace)

HS.xs <- HS[,7:15]
for(i in 1:9){
HS.xs[,i] = ifelse(HS.xs[,i] < mean(HS.xs[,i]), 0, 1)
}
#summary(HS.xs)

mydata = data.frame(HS[,1:5])
mydata$scale <- as.matrix(HS.xs)
```


Run it
```{r}
RT_out <- raschtree(scale ~ sex + ageyr + school, data = mydata)
RT_out
# summary(RT_out)
```

Plot it
```{r}
plot(RT_out,col = rainbow_hcl(9))
```


More output from raschtree
```{r}
itempar(RT_out,node=1) # what would it be if no split
itempar(RT_out, node = 2)
itempar(RT_out, node=3)


coef(RT_out, node = 2)
```




# Tutz DIFlasso

http://link.springer.com/article/10.1007%2Fs11336-013-9377-6

```{r,message=FALSE}
library(DIFlasso)

Y <- data.frame(mydata$scale)
X <- sapply(HS[,1:3],as.numeric)
X.std <- data.frame(scale(X))
mlas1 <- DIFlasso(Y,X.std)
print(mlas1)
```

```{r}
plot(mlas1)
```


Can re-fit (Code causes Tex problem)
```{r,eval=FALSE}
mlas2 <- refitDIFlasso(mlas1)
mlas2
plot(mlas2)
```


# Magis DIF Lasso

first load lassoDIF.R script and run functions

http://jeb.sagepub.com/content/early/2014/12/16/1076998614559747.abstract


Have to reformat dataset -- kinda weird
(this is common with some IRT packages -- particularly using mixed models for IRT)
* each row is one item response with columns corresponding to:\
** item number\
** id number\
** values on covariates\

First reshape data
```{r}
HS$grade[is.na(HS$grade)] <- 7
library(reshape2)
# have to add ID variable that is a factor
hs.wide <- data.frame(HS[,1:4],HS.xs)
hs.wide$sum <- rowSums(HS.xs)
hs.wide$id <- as.factor(1:301)
HS$id <- as.factor(1:301)
xs <- c("x1","x2","x3","x4","x5","x6","x7","x8","x9")
hs.long <- melt(hs.wide, id.vars=c("id"),measure.vars =xs,variable.name="ITEM")

hs.long$school <- NA
hs.long$ageyr <- NA
hs.long$grade <- NA
hs.long$sex <- NA
hs.long$SCORE <- NA
for(i in 1:301){
  hs.long[hs.long$id == i,]$school <- HS[HS$id == i,]$school
  hs.long[hs.long$id == i,]$ageyr <- HS[HS$id == i,]$ageyr
  hs.long[hs.long$id == i,]$grade <- HS[HS$id == i,]$grade
  hs.long[hs.long$id == i,]$sex <- HS[HS$id == i,]$sex
  hs.long[hs.long$id == i,]$SCORE <- hs.wide[hs.wide$id == i,]$sum
}
names(hs.long)[3] <- "Y"
```

Dataset is set up, now have to change variable names in lassoDIF.R

 -- right now, only can use one covariate at a time
 
Change lines 7 and 63 in lassoDIF.R to reflect covariate names

## Important: Have to source() the lassoDIF.R code

```{r}
source("/Users/RJacobucci/Documents/Github/ATI_Labs/lassoDIF.R") # change path
out = lassoDIF(hs.long)
#lassoDIF.coef(out)
lassoDIF.ABWIC(out)
lassoDIF.CV(out,hs.long)
```


# Mixture Rasch Models


http://www2.uaem.mx/r-mirror/web/packages/psychomix/vignettes/raschmix.pdf
\
http://epm.sagepub.com/content/early/2014/06/20/0013164414536183
```{r}
library(psychomix)
hs.mat <- as.matrix(HS.xs)
m1 <- raschmix(hs.mat,k=1); BIC(m1)
m2 <- raschmix(hs.mat,k=2); BIC(m2) # best BIC
m3 <- raschmix(hs.mat,k=3); BIC(m3)
m4 <- raschmix(hs.mat,k=4); BIC(m4)

# won't give class for people with all wrong or right
hs.mat2 <- data.frame(hs.mat)
hs.mat2$sum <- rowSums(hs.mat)
hs.mat3 <- HS[hs.mat2$sum != 0 & hs.mat2$sum != 9,]
```

How do our derived classes correspond to covariates
```{r}
library(psych)
cor(hs.mat3$ageyr,m2@cluster)
tetrachoric(data.frame(hs.mat3$sex,m2@cluster))
cor(hs.mat3$grade[1:273],m2@cluster[1:273])
tetrachoric(data.frame(as.numeric(hs.mat3$school),m2@cluster)) # highest
```

Do we get similar results using the original dataset (back to CFA model)?

# Factor Mixture Models in OpenMx

-- only package to do it in R (I think?)

```{r}

resVars <-  mxPath(from=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=2,
                        free=TRUE,
                        values=c(1.1,1.3,1.2,.4,.5,.35,1.1,1,.9),
                        labels=c("e1","e2","e3","e4","e5","e6","e7","e8","e9"))

latVars <- mxPath(from="F1",
                        arrows=2,
                        free=TRUE,
                        values=0.26,
                        labels ="varF1")

manMeans <- mxPath(from="one",
                        to=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=1,
                        free=c(TRUE,TRUE,TRUE,TRUE,T,T,T,T,T),
                        values=c(4.93,6,2.2,3,4.3,2.1,4.1,5.5,5.3),
                        labels =c("meanx1","meanx2","meanx3","meanx4","meanx5",
                                  "meanx6","meanx7","meanx8","meanx9"))

loadings <- mxPath(from="F1",
                        to=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=1,
                        free=c(FALSE,T,T,T,T,T,T,T,T),
                        values=c(1,0.5,0.5,1.9,2.1,1.8,0.4,0.4,0.6),
                        labels =c("l1","l2","l3","l4","l5","l6","l7","l8","l9"))

latMeans <- mxPath(from="one", to="F1", arrows=1,
                    free=TRUE, values=0, labels="meanF1")

funML <- mxFitFunctionML(vector=TRUE)


class1 <- mxModel("Class1", type="RAM",
                  manifestVars=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                  latentVars="F1",resVars,loadings,manMeans,latMeans,latVars,funML)

latVars2 <- mxPath(from="F1",
                        arrows=2,
                        free=TRUE,
                        values=2,
                        labels ="varF2")
# latent means
latMeans2 <- mxPath(from="one", to="F1", arrows=1,
                    free=TRUE, values=2, labels="meanF12")

class2 <- mxModel(class1, name="Class2", latVars2, latMeans2)

classP <- mxMatrix(type="Full", nrow=2, ncol=1,
                  free=c(TRUE, FALSE), values=1, lbound=0.001,
                  labels = c("p1","p2"), name="Props")

classS <- mxAlgebra( Props %x% (1/sum(Props)), name="classProbs" )

algFit <- mxAlgebra(-2*sum(log(classProbs[1,1] %x% Class1.fitfunction
                    + classProbs[2,1] %x% Class2.fitfunction)),
                    name="mixtureObj")

fit <- mxFitFunctionAlgebra("mixtureObj")
data <- mxData(observed=HS,type="raw")
fmm <- mxModel("Factor Mixture Model",
                data, class1, class2, classP, classS, algFit, fit)
fmmFit <- mxRun(fmm, suppressWarnings=TRUE)
# summary(fmmFit)
fmmFit$classProbs

#str(fmmFit)

fmmFit$submodels$Class2$fitfunction$likelihoods
comp <- fmmFit$output$algebras$Class1.fitfunction > fmmFit$output$algebras$Class2.fitfunction
sum(comp)/301


# http://openmx.psyc.virginia.edu/thread/717
indClassProbs <- function(model, classProbs, round=NA){
  # this function takes a mixture model in OpenMx
  # and returns the posterior class probabilities
	# using Bayes rule, individual person-class likelihoods
	# and the model class probability matrix, as described in
	# Ramaswamy, Desarbo, Reibstein, and Robinson, 1993
	cp <- mxEval(classProbs, model)
	cp2 <- as.vector(cp)
	cps <- diag(length(cp2))
	diag(cps) <- cp2
	subs <- model@submodels
	if(min(dim(cp))!=1)stop("Class probabilities matrix must be a row or column vector.")
	if(max(dim(cp))==1)stop("Class probabilities matrix must contain two or more classes.")
	of <- function(num){
		return(mxEval(objective, subs[[num]]))
		}
	rl <- sapply(1:length(names(subs)), of)
	raw <- (rl%*%cps)
	tot <- 1/apply(raw, 1, sum)
	div <- matrix(rep(tot, length(cp2)), ncol=length(cp2))
	icp <- raw * div
	if (is.numeric(round)){icp <- round(icp, round)}
	return(icp)
	}

#indClassProbs(fmmFit,fmmFit$classProbs)


prbs <- indClassProbs(fmmFit,fmmFit$classProbs)[,1]

HS$prbs <- prbs
lmm = lm(prbs ~ sex + ageyr + school + grade, data=HS)
summary(lmm)

cor(prbs,HS$sex)
cor(prbs,HS$ageyr)
cor(prbs,as.numeric(HS$school))
cor(prbs[1:300],HS$grade[1:300])

# compare 2 derived classes from both mixture models
cor(m2@cluster,prbs[hs.mat2$sum != 0 & hs.mat2$sum != 9])
```
The answer is no.


Moderation Try with OpenMx
-  how you specify the use of a covariate in OpenMx

```{r,eval=FALSE}

resVars <-  mxPath(from=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=2,
                        free=TRUE,
                        values=c(1.1,1.3,1.2,.4,.5,.35,1.1,1,.9),
                        labels=c("e1","e2","e3","e4","e5","e6","e7","e8","e9"))

latVars <- mxPath(from="F1",
                        arrows=2,
                        free=TRUE,
                        values=0.26,
                        labels ="varF1")

manMeans <- mxPath(from="one",
                        to=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=1,
                        free=c(TRUE,TRUE,TRUE,TRUE,T,T,T,T,T),
                        values=c(4.93,6,2.2,3,4.3,2.1,4.1,5.5,5.3),
                        labels =c("meanx1","meanx2","meanx3","meanx4","meanx5",
                                  "meanx6","meanx7","meanx8","meanx9"))

loadings <- mxPath(from="F1",
                        to=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),
                        arrows=1,
                        free=c(FALSE,T,T,T,T,T,T,T,T),
                        values=c(1,0.5,0.5,1.9,2.1,1.8,0.4,0.4,0.6),
                        labels =c("l1","l2","l3","l4","l5","l6","l7","l8","l9"))

latMeans <- mxPath(from="one", to="F1", arrows=1,
                    free=TRUE, values=0, labels="meanF1")

defValues    <- mxPath( from="one", to="DefDummy", arrows=1, 
                        free=FALSE, values=1, labels="data.sex" )

# beta weights
betaWeights  <- mxPath( from="DefDummy", to=c("F1"), arrows=1, 
                        free=TRUE, values=1, labels=c("beta_1") )

#LoadsDef           <- mxAlgebra(expression= l2 + beta*ageyr, name="l22" )


funML <- mxFitFunctionML()

HS.def <- HS[,c(2,7:15)]
HS.def$sex <- mxFactor(HS.def$sex,levels=c(1,2))

data <- mxData(observed=HS.def,type="raw")

Onefac <- mxModel("One fac mod",type="RAM",
                manifestVars=c("x1","x2","x3","x4","x5","x6","x7","x8","x9"),data,
                  latentVars=c("F1","DefDummy"),resVars,loadings,manMeans,latMeans,latVars,funML,
                betaWeights,defValues)
MxOut <- mxTryHard(Onefac)
summary(MxOut)


```